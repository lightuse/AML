{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automated Machine Learning Binary Classification with function.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lightuse/AML/blob/master/Automated_Machine_Learning_Binary_Classification_with_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCfSgMMqcj74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RE0ZvFQa5gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDxqt439humu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from common import function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZQ0VKbF0TBSm"
      },
      "source": [
        "# supervised learning\n",
        "## binary classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4KpVSXzW8-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2VLl-w9W2BX0"
      },
      "source": [
        "Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W6adj8nKyT9L",
        "colab": {}
      },
      "source": [
        "# set pipelines for different algorithms\n",
        "evaluation_list = {'AUC':'roc_auc',\n",
        "                   'F1':'f1',\n",
        "                   'Recall':'recall',\n",
        "                   'Precision':'precision',\n",
        "                   'Accuracy':'accuracy'}\n",
        "evaluation_function_list = {'AUC':roc_auc_score,\n",
        "                            'F1':f1_score,\n",
        "                            'Recall':recall_score,\n",
        "                            'Precision':precision_score,\n",
        "                            'Accuracy':accuracy_score}\n",
        "options_evaluation = ['Accuracy', 'AUC', 'F1', 'Recall', 'Precision']\n",
        "options_algorithm = ['lightgbm', 'knn', 'rsvc', 'logistic', 'rf', 'gb', 'mlp', 'xgboost', 'catboost']\n",
        "# 出力を predict_proba にするか \n",
        "is_predict_proba = False\n",
        "# \n",
        "is_one_hot_encoding = True\n",
        "is_imputation = False\n",
        "exception_algorithm_list = ['tree', 'knn', 'xgboost', 'logistic', 'rsvc', 'rf', 'gb', 'mlp', 'catboost']\n",
        "pipelines = {\n",
        "    'lightgbm':\n",
        "        Pipeline([('pca', PCA(random_state=1)),\n",
        "                  ('est', lgb.LGBMClassifier(random_state=1))]),\n",
        "    'xgboost':\n",
        "        Pipeline([('pca', PCA(random_state=1)),\n",
        "                  ('est', xgb.XGBClassifier(random_state=1))]),\n",
        "    'catboost':\n",
        "        Pipeline([('pca', PCA(random_state=1)),\n",
        "                  ('est', CatBoostClassifier(random_state=1))]),\n",
        "    'knn':\n",
        "        Pipeline([('scl', StandardScaler()),\n",
        "                  ('pca', PCA(random_state=1)),\n",
        "                  ('est', KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski'))]),\n",
        "    'logistic':\n",
        "        Pipeline([('scl', StandardScaler()),\n",
        "                  ('pca', PCA(random_state=1)),\n",
        "                  ('est', LogisticRegression(random_state=1))]),\n",
        "    'rsvc':\n",
        "        Pipeline([('scl', StandardScaler()),\n",
        "                  ('pca', PCA(random_state=1)),\n",
        "                  ('est', SVC(C=1.0, kernel='rbf', class_weight='balanced', probability=is_predict_proba, random_state=1))]),\n",
        "    'tree':\n",
        "        Pipeline([('pca', PCA(random_state=1)),\n",
        "                  ('est', DecisionTreeClassifier(random_state=1))]),\n",
        "    'rf':\n",
        "        Pipeline([('pca', PCA(random_state=1)),\n",
        "                  ('est', RandomForestClassifier(random_state=1))]),\n",
        "    'gb':\n",
        "        Pipeline([('pca', PCA(random_state=1)),\n",
        "                  ('est', GradientBoostingClassifier(random_state=1))]),\n",
        "    'mlp':\n",
        "        Pipeline([('scl', StandardScaler()),\n",
        "                  ('pca', PCA(random_state=1)),\n",
        "                  ('est', MLPClassifier(hidden_layer_sizes=(3,3), max_iter=10000, random_state=1))])\n",
        "}\n",
        "\n",
        "if not is_one_hot_encoding:\n",
        "    if 'lightgbm' in pipelines:\n",
        "        pipelines.pop('lightgbm')\n",
        "    if 'xgboost' in pipelines:\n",
        "        pipelines.pop('xgboost')\n",
        "    if 'knn' in pipelines:\n",
        "        pipelines.pop('knn')\n",
        "    if 'logistic' in pipelines:\n",
        "        pipelines.pop('logistic')\n",
        "    if 'rsvc' in pipelines:\n",
        "        pipelines.pop('rsvc')\n",
        "    if 'mlp' in pipelines:\n",
        "        pipelines.pop('mlp')\n",
        "\n",
        "for algorithm in exception_algorithm_list:\n",
        "    if algorithm in pipelines:\n",
        "        pipelines.pop(algorithm)\n",
        "\n",
        "# Feature selection by RandomForestClassifier\n",
        "feature_selection_rf_list = ['knn', 'logistic', 'rsvc', 'mlp']\n",
        "feature_importances_algorithm_list = ['tree', 'rf', 'gb', 'lightgbm', 'xgboost', 'catboost']\n",
        "tuning_prarameter_list = ['gb', 'lightgbm', 'rf']\n",
        "tuning_prarameter_list = []\n",
        "# パラメータグリッドの設定\n",
        "tuning_prarameter = {\n",
        "    'lightgbm':{\n",
        "        'est__learning_rate': [0.1,0.05,0.01],\n",
        "        'est__n_estimators':[1000,2000],\n",
        "        'est__num_leaves':[31,15,7,3],\n",
        "        'est__max_depth':[4,8,16]\n",
        "    },\n",
        "    'tree':{\n",
        "        \"est__min_samples_split\": [10, 20, 40],\n",
        "        \"est__max_depth\": [2, 6, 8],\n",
        "        \"est__min_samples_leaf\": [20, 40, 100],\n",
        "        \"est__max_leaf_nodes\": [5, 20, 100],\n",
        "    },\n",
        "    'rf':{\n",
        "        'est__n_estimators':[5,10,20,50,100],\n",
        "        'est__max_depth':[1,2,3,4,5],\n",
        "    },\n",
        "    'knn':{\n",
        "        'est__n_neighbors':[1,2,3,4,5,],\n",
        "        'est__weights':['uniform','distance'],\n",
        "        'est__algorithm':['auto','ball_tree','kd_tree','brute'],\n",
        "        'est__leaf_size':[1,10,20,30,40,50],\n",
        "        'est__p':[1,2]\n",
        "    },\n",
        "    'logistic':{\n",
        "        'pca__n_components':[5,7,9],\n",
        "        'est__C':[0.1,1.0,10.0,100.0]\n",
        "    },\n",
        "    'gb':{\n",
        "        'est__loss':['deviance','exponential'],\n",
        "        'est__n_estimators':[5,10,50,100,500],\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y192l2ROoxMM",
        "colab": {}
      },
      "source": [
        "# 表示オプションの変更\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 100)\n",
        "# カテゴリ変数をリストで設定\n",
        "ohe_columns = ['lobby-mode',\n",
        "               'mode',\n",
        "               'stage',\n",
        "               'A1-weapon',\n",
        "               'A1-rank',\n",
        "               'A2-weapon',\n",
        "               'A2-rank',\n",
        "               'A3-weapon',\n",
        "               'A3-rank',\n",
        "               'A4-weapon',\n",
        "               'A4-rank',\n",
        "               'B1-weapon',\n",
        "               'B1-rank',\n",
        "               'B2-weapon',\n",
        "               'B2-rank',\n",
        "               'B3-weapon',\n",
        "               'B3-rank',\n",
        "               'B4-weapon',\n",
        "               'B4-rank',\n",
        "            ]\n",
        "# カテゴリ変数をobject型で読み込むための準備\n",
        "my_dtype = {'game-ver':object,\n",
        "               'lobby-mode':object,\n",
        "               'lobby':object,\n",
        "               'mode':object,\n",
        "               'stage':object,\n",
        "               'A1-weapon':object,\n",
        "               'A1-rank':object,\n",
        "               'A2-weapon':object,\n",
        "               'A2-rank':object,\n",
        "               'A3-weapon':object,\n",
        "               'A3-rank':object,\n",
        "               'A4-weapon':object,\n",
        "               'A4-rank':object,\n",
        "               'B1-weapon':object,\n",
        "               'B1-rank':object,\n",
        "               'B2-weapon':object,\n",
        "               'B2-rank':object,\n",
        "               'B3-weapon':object,\n",
        "               'B3-rank':object,\n",
        "               'B4-weapon':object,\n",
        "               'B4-rank':object,\n",
        "               'A1-level':float,\n",
        "               'A2-level':float,\n",
        "               'A3-level':float,\n",
        "               'A4-level':float,\n",
        "               'B1-level':float,\n",
        "               'B2-level':float,\n",
        "               'B3-level':float,\n",
        "               'B4-level':float,\n",
        "            }\n",
        "id_label = 'id'\n",
        "target_label = 'y'\n",
        "drop_columns = ['game-ver', 'lobby']\n",
        "out_put_data_dir = \"/content/drive/My Drive/Colab Notebooks/game_winner/data/\"\n",
        "train_file_name = out_put_data_dir + 'train_data.csv'\n",
        "test_file_name = out_put_data_dir + 'test_data.csv'\n",
        "model_columns_file_name = out_put_data_dir + 'model_columns.csv'\n",
        "# feature_selection range 50-100\n",
        "n_features_to_select = 200\n",
        "# ファイル出力拡張子\n",
        "file_extention = 'csv'\n",
        "# ホールドアウト有無\n",
        "is_holdout = False\n",
        "# k-fold 法を利用するか\n",
        "is_k_fold = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuKJIFseovOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "is_optuna = False\n",
        "is_header = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pTTNkzAE2FWH",
        "colab": {}
      },
      "source": [
        "def input_train_file(filename, my_dtype):\n",
        "    df = pd.read_csv(train_file_name, header=0, dtype=my_dtype)\n",
        "    # データの形式に合わせて適時修正\n",
        "    df = df.drop(id_label, axis=1)\n",
        "    y = df.iloc[:,-1]\n",
        "    class_mapping = {0:0, 1:1}\n",
        "    y = y.map(class_mapping)\n",
        "    X = df.drop(target_label, axis=1)\n",
        "    X = X.reset_index(drop=True)\n",
        "    print('欠損個数（数値変数の欠損補完前）:input_train_file', X.isnull().sum().sum())\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7rqBCH5vs3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import re\n",
        "import numpy as np\n",
        "def transform_data(X:pd.core.series.Series):\n",
        "    X['period'] =  pd.to_datetime(X['period']).map(pd.Timestamp.to_julian_date)\n",
        "    publishedAt = pd.to_datetime(X['period'], utc=True)\n",
        "    X[\"year\"] = publishedAt.apply(lambda x: x.year)\n",
        "    X[\"month\"] = publishedAt.apply(lambda x: x.month)\n",
        "    X[\"day\"] = publishedAt.apply(lambda x: x.day)\n",
        "    X[\"week\"] = publishedAt.apply(lambda x: x.weekday())\n",
        "    for column in ohe_columns:\n",
        "        X['frequency_encode_' + column] = function.convert_to_frequency_encode(X, column)\n",
        "        #X['label_encode_' + column] = function.convert_to_label_encode(X, column)\n",
        "        X['count_encode_' + column] = function.convert_to_count_encode(X, column)\n",
        "        X['label_count_encode_' + column] = function.convert_to_label_count_encode(X, column)\n",
        "    # 不要カラム削除\n",
        "    for column in drop_columns:\n",
        "        X = X.drop(column, axis=1)\n",
        "    X = X.reset_index(drop=True)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rjP_XkkP2rXU"
      },
      "source": [
        "Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C2_BTK_G2TZE",
        "colab": {}
      },
      "source": [
        "import optuna.integration.lightgbm as lgb\n",
        "from joblib import dump\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# train\n",
        "def train_model(X, y, X_ohe_columns, evaluation):\n",
        "    for pipe_name, pipeline in pipelines.items():\n",
        "        print(pipe_name)\n",
        "        if pipe_name in feature_selection_rf_list:\n",
        "            X_featured = function.feature_selection(out_put_data_dir, n_features_to_select, X, y, X_ohe_columns, pipe_name, pipelines['rf'].named_steps['est'])\n",
        "        else:\n",
        "            X_featured = function.feature_selection(out_put_data_dir, n_features_to_select, X, y, X_ohe_columns, pipe_name, pipeline.named_steps['est'])\n",
        "        if is_holdout:\n",
        "            X_train, X_valid, y_train, y_valid = function.holdout(X_featured, y)\n",
        "        else:\n",
        "            X_train, X_valid, y_train, y_valid = X_featured, X_featured, y, y\n",
        "        if pipe_name in tuning_prarameter_list:\n",
        "            gs = GridSearchCV(estimator=pipeline,\n",
        "                        param_grid=tuning_prarameter[pipe_name],\n",
        "                        scoring=evaluation_list[evaluation],\n",
        "                        cv=3,\n",
        "                        return_train_score=False)\n",
        "            gs.fit(X_train, y_train)\n",
        "            dump(gs, out_put_data_dir + pipe_name + '_classiffier.joblib')\n",
        "            gs.fit(X_valid, y_valid)\n",
        "            # 探索した結果のベストスコアとパラメータの取得\n",
        "            print(pipe_name + ' Best Score:', gs.best_score_)\n",
        "            print(pipe_name + ' Best Params', gs.best_params_)\n",
        "        else:\n",
        "            if is_optuna and pipe_name in 'lightgbm':\n",
        "                lgb_train = lgb.Dataset(X_train, (y_train))\n",
        "                lgb_eval = lgb.Dataset(X_valid, (y_valid), reference=lgb_train)\n",
        "                params = {\n",
        "                    'objective': 'binary',\n",
        "                    'metric': 'binary_logloss',\n",
        "                }\n",
        "                best = lgb.train(params,\n",
        "                            lgb_train,\n",
        "                            valid_sets=[lgb_train, lgb_eval],\n",
        "                            verbose_eval=0)\n",
        "                dump(best, out_put_data_dir + pipe_name + '_classiffier.joblib')\n",
        "            else:\n",
        "                clf = pipeline.fit(X_train, y_train)\n",
        "                dump(clf, out_put_data_dir + pipe_name + '_classiffier.joblib')\n",
        "                if is_holdout:\n",
        "                    clf = pipeline.fit(X_valid, y_valid)\n",
        "    return X_train, X_valid, y_train, y_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Otjg8_z5iNkF"
      },
      "source": [
        "Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CP46pKAniJ0W",
        "colab": {}
      },
      "source": [
        "from joblib import load\n",
        "def scoring(algorithm_name :str, X, is_predict_proba = False):\n",
        "    clf = load(out_put_data_dir + algorithm_name + '_classiffier.joblib')\n",
        "    if is_optuna:\n",
        "        return clf.predict(X)\n",
        "    if is_predict_proba:\n",
        "        return clf.predict_proba(X)[:, 1]\n",
        "    return clf.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I0bdyUa4qq2n",
        "colab": {}
      },
      "source": [
        "def evaluation(scores, X_train, y_train, text, evaluation_function_list, input_evaluation, is_predict_proba):\n",
        "    for pipe_name, pipeline in pipelines.items():\n",
        "        if input_evaluation.value == 'Accuracy':\n",
        "            scores[(pipe_name, text)] = evaluation_function_list[input_evaluation.value](y_train, scoring(pipe_name, X_train, is_predict_proba).round())\n",
        "        else:\n",
        "            scores[(pipe_name, text)] = evaluation_function_list[input_evaluation.value](y_train, scoring(pipe_name, X_train, is_predict_proba))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zZuSFEidmqPT",
        "colab": {}
      },
      "source": [
        "input_evaluation = function.choice(options_evaluation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0nIw7PEVPt20",
        "colab": {}
      },
      "source": [
        "X, y = input_train_file(train_file_name, my_dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig6JybDmvXDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = transform_data(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdDkapVu3JHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ohe = function.one_hot_encoding(X, ohe_columns)\n",
        "X_ohe.to_csv(out_put_data_dir + \"X_ohe.csv\", index=False, header=True)\n",
        "print('欠損個数（数値変数の欠損補完前）', X_ohe.isnull().sum().sum())\n",
        "print('')\n",
        "print(X_ohe.isnull().sum())\n",
        "X_ohe, X_ohe_columns = function.imputation(out_put_data_dir, model_columns_file_name, X_ohe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-1iNCeWTjRa",
        "colab_type": "text"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8yBQ3rQiZbDh",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_model(X_ohe, y, X_ohe_columns, input_evaluation.value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FFU6vIcCbMOv"
      },
      "source": [
        "CV Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y5abYEsQZ6sH",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "str_all_print = 'n_features_to_select:' + str(n_features_to_select) + '\\n'\n",
        "if is_k_fold:\n",
        "    print('評価指標:' + input_evaluation.value)\n",
        "    str_print = ''\n",
        "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "    for pipe_name, est in pipelines.items():\n",
        "        cv_results = cross_val_score(est,\n",
        "                                    X_ohe, y,\n",
        "                                    cv=kf,\n",
        "                                    scoring=evaluation_list[input_evaluation.value])  \n",
        "        str_print = '----------' + '\\n' + 'algorithm:' + str(pipe_name) + '\\n' + 'cv_results:' + str(cv_results) + '\\n' + 'avg +- std_dev ' + str(cv_results.mean()) + '+-' + str(cv_results.std()) + '\\n'\n",
        "        print(str_print)\n",
        "        str_all_print += str_print\n",
        "    import datetime\n",
        "    with open(out_put_data_dir + 'cv_results' + '_' + datetime.datetime.now().strftime('%Y%m%d%H%M%S') + '.txt', mode='w') as f:\n",
        "        f.write(str_all_print)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lzzb_D_EbIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if is_optuna:\n",
        "    import optuna.integration.lightgbm as lgb\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    dtrain = lgb.Dataset(X_ohe, label=y)\n",
        "    params = {\n",
        "        \"objective\": \"binary\",\n",
        "        \"metric\": \"binary_logloss\",\n",
        "        \"verbosity\": -1,\n",
        "        \"boosting_type\": \"gbdt\",\n",
        "    }\n",
        "    tuner = lgb.LightGBMTunerCV(\n",
        "        params, dtrain, verbose_eval=100, early_stopping_rounds=100, folds=StratifiedKFold(n_splits=3)\n",
        "    )\n",
        "    tuner.run()\n",
        "    print(\"Best score:\", tuner.best_score)\n",
        "    best_params = tuner.best_params\n",
        "    print(\"Best params:\", best_params)\n",
        "    print(\"  Params: \")\n",
        "    for key, value in best_params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hw6FhMrAmCbe",
        "colab": {}
      },
      "source": [
        "scores = {}\n",
        "if is_holdout:\n",
        "    evaluation(scores, X_train, y_train, 'train', evaluation_function_list, input_evaluation, is_predict_proba)\n",
        "    evaluation(scores, X_valid, y_valid, 'valid', evaluation_function_list, input_evaluation, is_predict_proba)\n",
        "else:\n",
        "    evaluation(scores, X_train, y_train, 'train', evaluation_function_list, input_evaluation, is_predict_proba)\n",
        "print('評価指標:' + input_evaluation.value)\n",
        "if is_holdout:\n",
        "    display(pd.Series(scores).unstack().sort_values(by=['train', 'valid']))\n",
        "else:\n",
        "    display(pd.Series(scores).unstack().sort_values(by=['train']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WbjWPvuEcfUa",
        "colab": {}
      },
      "source": [
        "def input_test_file(filename, my_dtype, id_label):\n",
        "    df_s = pd.read_csv(filename, header=0, dtype=my_dtype)\n",
        "    X_s  = df_s.drop(id_label, axis=1)\n",
        "    df_s = df_s.reset_index(drop=True)\n",
        "    return df_s, X_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9xaTzyIzTcnX",
        "colab": {}
      },
      "source": [
        "input_algorithm = function.choice(options_algorithm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1HW5647I4KCB",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "# 永続化したデータ読込し、 同じ評価指標ではtrain_modelは一度のみ実行で、かつ、選択されたモデルでスコアリングする\n",
        "def main():\n",
        "    algorithm_name = input_algorithm.value\n",
        "    df_s, X_s = input_test_file(test_file_name, my_dtype, id_label)\n",
        "    X_s = transform_data(X_s)\n",
        "    X_ohe_s = function.one_hot_encoding(X_s, ohe_columns)\n",
        "    X_predicted = function.preprocessing(out_put_data_dir, model_columns_file_name, algorithm_name, X_ohe, X_ohe_s)\n",
        "    predict = scoring(algorithm_name, X_predicted, is_predict_proba);\n",
        "    function.output_file(out_put_data_dir, n_features_to_select, target_label, df_s, id_label, predict, algorithm_name, file_extention, header=is_header)\n",
        "    print(input_evaluation.value + ' selected')\n",
        "    print(algorithm_name + ' selected')\n",
        "    if algorithm_name in feature_importances_algorithm_list:\n",
        "        if is_optuna and algorithm_name == 'lightgbm':\n",
        "            ;\n",
        "        else:\n",
        "            feature_importances = pipelines[algorithm_name]['est'].feature_importances_\n",
        "            feature_importances = pd.Series(feature_importances, index=X_predicted.columns.values.tolist())\n",
        "            sorted_feature_importances = sorted(feature_importances.items(), key=lambda x:-x[1])\n",
        "            sorted_feature_importances = pd.DataFrame(sorted_feature_importances)\n",
        "            sorted_feature_importances.to_csv(out_put_data_dir + 'feature_importances_' + algorithm_name + '_' + datetime.datetime.now().strftime('%Y%m%d%H%M%S') + '.csv', index=False)\n",
        "            display(sorted_feature_importances)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nalehpK6jyoH",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}